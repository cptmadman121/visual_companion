# TrayVisionPrompt

TrayVisionPrompt ist ein leichtgewichtiges Windows 10/11 Tray-Companion, das markierte Bildschirmbereiche per globalem Hotkey erfasst, Annotationen erlaubt und den Screenshot zusammen mit einem Prompt an einen lokalen LLM-Server sendet. Die Antwort wird als Pop-Up angezeigt und kann in die Zwischenablage kopiert werden.

## Features
- ğŸ–¥ï¸ System-Tray-App mit KontextmenÃ¼ (Einstellungen, Backend testen, letzte Antwort kopieren, Logs Ã¶ffnen, Beenden)
- âŒ¨ï¸ Konfigurierbarer globaler Hotkey (Standard: `Win+Shift+Q`)
- âœï¸ BildschirmÃ¼berlagerung zur Rechteckauswahl mit Ink-Annotationen (Undo/Reset)
- ğŸ“ Instruktionsdialog mit Prompt-Eingabe und Presets
- ğŸ¤– Adapterbasiertes LLM-Interface (Ollama, vLLM, llama.cpp)
- ğŸ§¾ Optionale OCR-Fallback-Verarbeitung Ã¼ber Windows.Media.Ocr
- ğŸ”’ Lokale Verarbeitung, Logging nach `%APPDATA%\TrayVisionPrompt`

## Projektstruktur
```
TrayVisionPrompt/
â”œâ”€â”€ TrayVisionPrompt.sln
â”œâ”€â”€ src/
â”‚   â””â”€â”€ TrayVisionPrompt/        # WPF-Anwendung (.NET 8)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ TrayVisionPrompt.Tests/  # xUnit-Tests
â”œâ”€â”€ tools/                       # Build- und Paket-Skripte
â”œâ”€â”€ Installer.md                 # Installationshinweise
â””â”€â”€ README.md
```

## Entwicklung
### Voraussetzungen
- Visual Studio 2022 (17.8+) mit .NET Desktop Development
- .NET 8 SDK
- Windows 10/11 x64

### Build & Test
```powershell
# Aus dem Projektstamm
pwsh tools/build.ps1
pwsh tools/build.ps1 -Release
pwsh -c "dotnet test TrayVisionPrompt.sln"
```

### Visual Studio Code
Die Datei `.vscode/tasks.json` definiert Build- und Test-Tasks, `.vscode/launch.json` startet die App nach einem Debug-Build.

## Konfiguration
Beim ersten Start wird `%APPDATA%\TrayVisionPrompt\config.json` erzeugt. Beispiel:
```json
{
  "hotkey": "Win+Shift+Q",
  "backend": "ollama",
  "endpoint": "http://192.168.201.166:11434/v1/chat/completions",
  "model": "llava:latest",
  "requestTimeoutMs": 45000,
  "maxTokens": 1024,
  "temperature": 0.2,
  "useVision": true,
  "useOcrFallback": true,
  "proxy": null,
  "telemetry": false,
  "logLevel": "Info"
}
```

## Backend-Anbindung
TrayVisionPrompt kommuniziert Ã¼ber eine OpenAI-kompatible `/chat/completions`-Route. Bilder werden als `data:image/png;base64` in `content.parts` Ã¼bergeben. Die Implementierungen sind austauschbar:
- **OllamaClient** â€“ Standard fÃ¼r Ollama Vision-Modelle (`llava`, `llava:latest`)
- **VllmClient** â€“ FÃ¼r vLLM-Instanzen mit Vision-Support
- **LlamaCppClient** â€“ FÃ¼r `llama.cpp server.exe`

Falls Vision deaktiviert ist, aber `useOcrFallback = true`, wird der OCR-Text als ErgÃ¤nzung gesendet.

## Logging & Datenschutz
- Serilog schreibt nach `%APPDATA%\TrayVisionPrompt\TrayVisionPrompt.log` (Rolling, 7 Tage)
- Keine Telemetrie oder externe Uploads; alle Requests laufen lokal
- Logs kÃ¶nnen Ã¼ber das Tray-MenÃ¼ geÃ¶ffnet werden

## Tests
```powershell
pwsh -c "dotnet test TrayVisionPrompt.sln"
```

## Installer
Siehe [Installer.md](Installer.md) fÃ¼r Paketierung, Installation und Update-Hinweise.

## Roadmap / Erweiterungen
- ZusÃ¤tzliche Backend-Adapter (REST, gRPC)
- Fortgeschrittene Annotationstools (Text, Pfeile, Formen)
- Automatische Erkennung mehrerer Monitore
- Erweiterte Markdown-Anzeige der LLM-Antwort
